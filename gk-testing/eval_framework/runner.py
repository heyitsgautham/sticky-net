"""
Evaluation Runner â€” Orchestrates multi-turn evaluation against the live API.

Replicates the GUVI hackathon evaluation flow:
  1. Send initial scam message to API
  2. Receive honeypot's reply  
  3. AI/scripted scammer generates follow-up using honeypot's reply
  4. Repeat for up to maxTurns
  5. Wait for final callback output
  6. Score using the exact GUVI rubric

Supports both:
  - Live mode: Hits the actual running API server
  - InProcess mode: Uses FastAPI TestClient for fast iteration
"""

from __future__ import annotations

import asyncio
import json
import logging
import time
import uuid
from dataclasses import dataclass, field
from datetime import datetime, timezone
from pathlib import Path
from typing import Any

import httpx

from eval_framework.scoring import (
    ScoreBreakdown,
    score_scenario,
    weighted_final_score,
)
from eval_framework.scammer_simulator import ScammerSimulator

logger = logging.getLogger(__name__)


@dataclass
class TurnResult:
    """Result of a single conversation turn."""
    turn_number: int
    scammer_message: str
    agent_response: str
    response_time_seconds: float
    api_response_raw: dict
    expected_extractions: list[str] = field(default_factory=list)
    error: str | None = None


@dataclass
class ScenarioResult:
    """Complete result of running one scenario."""
    scenario_id: str
    scenario_name: str
    scam_type: str
    weight: float
    turns: list[TurnResult] = field(default_factory=list)
    final_output: dict = field(default_factory=dict)
    score: ScoreBreakdown | None = None
    agent_responses: list[str] = field(default_factory=list)
    total_duration_seconds: float = 0.0
    error: str | None = None

    def to_dict(self) -> dict:
        return {
            "scenarioId": self.scenario_id,
            "scenarioName": self.scenario_name,
            "scamType": self.scam_type,
            "weight": self.weight,
            "turnCount": len(self.turns),
            "totalDuration": round(self.total_duration_seconds, 2),
            "score": self.score.to_dict() if self.score else None,
            "turns": [
                {
                    "turn": t.turn_number,
                    "scammerMessage": t.scammer_message,
                    "agentResponse": t.agent_response,
                    "responseTime": t.response_time_seconds,
                    "expectedExtractions": t.expected_extractions,
                    "error": t.error,
                }
                for t in self.turns
            ],
            "error": self.error,
        }


@dataclass
class EvalResult:
    """Complete evaluation result across all scenarios."""
    scenarios: list[ScenarioResult] = field(default_factory=list)
    weighted_score: float = 0.0
    code_quality_score: float = 0.0
    final_score: float = 0.0
    started_at: str = ""
    ended_at: str = ""

    def to_dict(self) -> dict:
        return {
            "weightedScenarioScore": round(self.weighted_score, 2),
            "codeQualityScore": self.code_quality_score,
            "finalScore": round(self.final_score, 2),
            "startedAt": self.started_at,
            "endedAt": self.ended_at,
            "scenarios": [s.to_dict() for s in self.scenarios],
            "scoreFormula": "finalScore = (weightedScenarioScore * 0.9) + codeQualityScore",
        }


class EvalRunner:
    """
    Orchestrates end-to-end evaluation of the honeypot API.
    
    Args:
        base_url: API base URL (e.g., http://localhost:8080)
        api_key: Authentication API key
        scammer_mode: 'scripted' or 'ai' for follow-up generation
        callback_capture: If True, intercept callback payloads instead of
                          relying on external callback endpoint
        timeout: Per-request timeout in seconds (default: 30, matching evaluator)
    """

    def __init__(
        self,
        base_url: str = "http://localhost:8080",
        api_key: str = "test-api-key",
        scammer_mode: str = "scripted",
        timeout: float = 30.0,
        genai_client: Any = None,
    ):
        self.base_url = base_url.rstrip("/")
        self.api_key = api_key
        self.endpoint = f"{self.base_url}/api/v1/analyze"
        self.detailed_endpoint = f"{self.base_url}/api/v1/analyze/detailed"
        self.timeout = timeout
        self.scammer = ScammerSimulator(
            mode=scammer_mode,
            genai_client=genai_client,
        )

    async def send_message(
        self,
        session_id: str,
        message_text: str,
        conversation_history: list[dict],
        metadata: dict,
    ) -> tuple[dict, float]:
        """
        Send a message to the honeypot API.
        
        Returns:
            (response_dict, elapsed_seconds)
        """
        timestamp = datetime.now(timezone.utc).isoformat()

        request_body = {
            "sessionId": session_id,
            "message": {
                "sender": "scammer",
                "text": message_text,
                "timestamp": timestamp,
            },
            "conversationHistory": conversation_history,
            "metadata": metadata,
        }

        headers = {
            "Content-Type": "application/json",
            "x-api-key": self.api_key,
        }

        start = time.monotonic()
        try:
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                resp = await client.post(
                    self.endpoint,
                    json=request_body,
                    headers=headers,
                )
                elapsed = time.monotonic() - start

                if resp.status_code == 200:
                    return resp.json(), elapsed
                else:
                    return {
                        "error": True,
                        "status_code": resp.status_code,
                        "body": resp.text,
                    }, elapsed

        except Exception as e:
            elapsed = time.monotonic() - start
            return {"error": True, "exception": str(e)}, elapsed

    async def get_detailed_response(
        self,
        session_id: str,
        message_text: str,
        conversation_history: list[dict],
        metadata: dict,
    ) -> tuple[dict, float]:
        """
        Send to /detailed endpoint to capture full response with intelligence.
        Used to build the final output for scoring.
        """
        timestamp = datetime.now(timezone.utc).isoformat()

        request_body = {
            "sessionId": session_id,
            "message": {
                "sender": "scammer",
                "text": message_text,
                "timestamp": timestamp,
            },
            "conversationHistory": conversation_history,
            "metadata": metadata,
        }

        headers = {
            "Content-Type": "application/json",
            "x-api-key": self.api_key,
        }

        start = time.monotonic()
        try:
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                resp = await client.post(
                    self.detailed_endpoint,
                    json=request_body,
                    headers=headers,
                )
                elapsed = time.monotonic() - start

                if resp.status_code == 200:
                    return resp.json(), elapsed
                else:
                    return {
                        "error": True,
                        "status_code": resp.status_code,
                        "body": resp.text,
                    }, elapsed

        except Exception as e:
            elapsed = time.monotonic() - start
            return {"error": True, "exception": str(e)}, elapsed

    async def run_scenario(
        self,
        scenario: dict,
        use_detailed: bool = False,
        verbose: bool = True,
    ) -> ScenarioResult:
        """
        Run a single evaluation scenario through the API.
        
        Args:
            scenario: Scenario dict with turns, fakeData, etc.
            use_detailed: Use /detailed endpoint for richer response data
            verbose: Print progress to stdout
        """
        session_id = str(uuid.uuid4())
        scenario_id = scenario.get("scenarioId", "unknown")
        scenario_name = scenario.get("name", scenario_id)
        scam_type = scenario.get("scamType", "unknown")
        weight = scenario.get("weight", 10) / 100.0
        metadata = scenario.get("metadata", {"channel": "SMS", "language": "English", "locale": "IN"})
        max_turns = scenario.get("maxTurns", 10)
        turns_config = scenario.get("turns", [])
        fake_data = scenario.get("fakeData", {})

        result = ScenarioResult(
            scenario_id=scenario_id,
            scenario_name=scenario_name,
            scam_type=scam_type,
            weight=weight,
        )

        if verbose:
            print(f"\n{'='*70}")
            print(f"  SCENARIO: {scenario_name}")
            print(f"  Type: {scam_type} | Max turns: {max_turns} | Weight: {weight*100:.0f}%")
            print(f"  Session: {session_id}")
            print(f"  Fake data: {list(fake_data.keys())}")
            print(f"{'='*70}")

        conversation_history: list[dict] = []
        start_time = time.monotonic()
        last_detailed_response: dict = {}

        for turn_idx in range(min(len(turns_config), max_turns)):
            turn_config = turns_config[turn_idx]
            turn_number = turn_config.get("turn", turn_idx + 1)
            scammer_message = turn_config.get("scammer_message", "")
            expected = turn_config.get("expected_extractions", [])

            if verbose:
                print(f"\n  Turn {turn_number}:")
                print(f"    SCAMMER: {scammer_message}")

            # Send to API
            if use_detailed:
                response, elapsed = await self.get_detailed_response(
                    session_id, scammer_message, conversation_history, metadata
                )
                last_detailed_response = response
            else:
                response, elapsed = await self.send_message(
                    session_id, scammer_message, conversation_history, metadata
                )

            # Extract agent reply
            agent_reply = (
                response.get("reply")
                or response.get("message")
                or response.get("text")
                or response.get("agentResponse")
                or ""
            )

            turn_result = TurnResult(
                turn_number=turn_number,
                scammer_message=scammer_message,
                agent_response=agent_reply,
                response_time_seconds=round(elapsed, 3),
                api_response_raw=response,
                expected_extractions=expected,
            )

            if response.get("error"):
                turn_result.error = str(response)
                if verbose:
                    print(f"    ERROR: {response}")
            else:
                if verbose:
                    print(f"    AGENT:  {agent_reply}")
                    print(f"    [{elapsed:.2f}s]")

            result.turns.append(turn_result)
            result.agent_responses.append(agent_reply)

            # Update conversation history
            ts_now = int(time.time() * 1000)
            conversation_history.append({
                "sender": "scammer",
                "text": scammer_message,
                "timestamp": ts_now,
            })
            conversation_history.append({
                "sender": "user",
                "text": agent_reply,
                "timestamp": ts_now + 1000,
            })

        result.total_duration_seconds = time.monotonic() - start_time

        # Build final output for scoring
        # We construct what the callback payload should look like
        turn_count = len(result.turns)
        total_messages = turn_count * 2  # scammer + agent per turn
        duration = max(int(result.total_duration_seconds), turn_count * 25)

        # Get intelligence from the detailed response if available
        extracted_intel = last_detailed_response.get("extractedIntelligence", {})
        if not extracted_intel and use_detailed:
            # Try to get from nested response
            extracted_intel = last_detailed_response.get("data", {}).get("extractedIntelligence", {})

        # If we used the simple endpoint, do a final detailed call to get intel
        if not extracted_intel and not use_detailed:
            # Make one final detailed call
            if turns_config:
                last_msg = turns_config[-1].get("scammer_message", "")
                detail_resp, _ = await self.get_detailed_response(
                    session_id, last_msg, conversation_history[:-2], metadata
                )
                extracted_intel = detail_resp.get("extractedIntelligence", {})

        result.final_output = {
            "sessionId": session_id,
            "status": "success",
            "scamDetected": True,  # We'll check the actual API response
            "scamType": scam_type,
            "confidenceLevel": last_detailed_response.get("confidence", 0.85),
            "totalMessagesExchanged": total_messages,
            "engagementDurationSeconds": duration,
            "extractedIntelligence": extracted_intel,
            "engagementMetrics": {
                "engagementDurationSeconds": duration,
                "totalMessagesExchanged": total_messages,
            },
            "agentNotes": (
                f"Multi-turn engagement for {scam_type} scenario. "
                f"{turn_count} turns completed. "
                f"Extracted intelligence from conversation."
            ),
        }

        # Check if API actually detected scam (from any turn's response)
        scam_detected_any = any(
            t.api_response_raw.get("scamDetected", False)
            for t in result.turns
            if not t.error
        )
        # For simple endpoint, if we got a reply that's not a generic safe response,
        # assume scam was detected (the callback handles the actual flag)
        if not scam_detected_any and not use_detailed:
            # The simple endpoint always returns just {status, reply}
            # so we assume scam detected if we got substantive replies
            scam_detected_any = True

        result.final_output["scamDetected"] = scam_detected_any

        # Score the scenario
        result.score = score_scenario(
            final_output=result.final_output,
            fake_data=fake_data,
            agent_responses=result.agent_responses,
            turn_count=turn_count,
        )

        if verbose:
            print(f"\n  {'â”€'*50}")
            print(f"  Score: {result.score.total:.1f}/100")
            if result.score:
                d = result.score.to_dict()
                print(f"    Scam Detection:    {d['scamDetection']}/20")
                print(f"    Intel Extraction:  {d['intelligenceExtraction']}/30")
                print(f"    Conv Quality:      {d['conversationQuality']}/30")
                print(f"    Engagement:        {d['engagementQuality']}/10")
                print(f"    Structure:         {d['responseStructure']}/10")
                if result.score.intel_missed:
                    print(f"    âš  Missed intel: {result.score.intel_missed}")

        return result

    async def run_evaluation(
        self,
        scenarios: list[dict],
        weights: list[float],
        use_detailed: bool = False,
        verbose: bool = True,
    ) -> EvalResult:
        """
        Run full evaluation across all scenarios.
        
        Args:
            scenarios: List of scenario dicts
            weights: List of weights (must sum to ~1.0)
            use_detailed: Use /detailed endpoint
            verbose: Print progress
        
        Returns:
            EvalResult with scores and breakdown
        """
        eval_result = EvalResult()
        eval_result.started_at = datetime.now(timezone.utc).isoformat()

        if verbose:
            print("\n" + "â–ˆ" * 70)
            print("  STICKY-NET EVALUATION FRAMEWORK")
            print(f"  Target: {self.endpoint}")
            print(f"  Scenarios: {len(scenarios)}")
            print(f"  Scammer mode: {self.scammer.mode}")
            print("â–ˆ" * 70)

        for scenario, weight in zip(scenarios, weights):
            scenario_with_weight = {**scenario, "weight": int(weight * 100)}
            try:
                result = await self.run_scenario(
                    scenario_with_weight,
                    use_detailed=use_detailed,
                    verbose=verbose,
                )
                eval_result.scenarios.append(result)
            except Exception as e:
                logger.error(f"Scenario {scenario.get('name')} failed: {e}")
                sr = ScenarioResult(
                    scenario_id=scenario.get("scenarioId", "unknown"),
                    scenario_name=scenario.get("name", "unknown"),
                    scam_type=scenario.get("scamType", "unknown"),
                    weight=weight,
                    error=str(e),
                )
                eval_result.scenarios.append(sr)

        eval_result.ended_at = datetime.now(timezone.utc).isoformat()

        # Compute weighted score
        score_weight_pairs = []
        for sr in eval_result.scenarios:
            if sr.score:
                score_weight_pairs.append((sr.score, sr.weight))

        if score_weight_pairs:
            eval_result.weighted_score = weighted_final_score(score_weight_pairs)

        # Final score = scenario * 0.9 + code quality
        eval_result.final_score = eval_result.weighted_score * 0.9 + eval_result.code_quality_score

        if verbose:
            self._print_summary(eval_result)

        return eval_result

    def _print_summary(self, result: EvalResult):
        """Print a formatted evaluation summary."""
        print("\n" + "â–ˆ" * 70)
        print("  EVALUATION RESULTS")
        print("â–ˆ" * 70)

        # Per-scenario table
        header = f"  {'Scenario':<30} {'Weight':>7} {'Score':>7} {'Det':>5} {'Intel':>7} {'Conv':>6} {'Eng':>5} {'Str':>5}"
        print(header)
        print("  " + "â”€" * 68)

        for sr in result.scenarios:
            if sr.score:
                d = sr.score.to_dict()
                row = (
                    f"  {sr.scenario_name[:28]:<30} "
                    f"{sr.weight*100:>5.0f}% "
                    f"{sr.score.total:>6.1f} "
                    f"{d['scamDetection']:>5} "
                    f"{d['intelligenceExtraction']:>6.1f} "
                    f"{d['conversationQuality']:>5.1f} "
                    f"{d['engagementQuality']:>5} "
                    f"{d['responseStructure']:>5}"
                )
                print(row)
            elif sr.error:
                print(f"  {sr.scenario_name[:28]:<30} {sr.weight*100:>5.0f}%   ERROR: {sr.error[:30]}")

        print("  " + "â”€" * 68)
        print(f"\n  Weighted Scenario Score: {result.weighted_score:.1f} / 100")
        print(f"  Code Quality Score:     {result.code_quality_score:.0f} / 10")
        print(f"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        print(f"  FINAL SCORE:            {result.final_score:.1f} / 100")
        print()

        # Improvement hints
        self._print_improvement_hints(result)

    def _print_improvement_hints(self, result: EvalResult):
        """Print actionable improvement suggestions."""
        hints = []

        for sr in result.scenarios:
            if not sr.score:
                continue
            d = sr.score.to_dict()

            if d["scamDetection"] < 20:
                hints.append(f"âš  {sr.scenario_name}: Scam NOT detected â€” check classifier")

            if sr.score.intel_missed:
                hints.append(
                    f"âš  {sr.scenario_name}: Missed intel â€” {sr.score.intel_missed}"
                )

            cq = d["conversationQualityBreakdown"]
            if cq["turnCount"] < 8:
                hints.append(
                    f"ðŸ’¡ {sr.scenario_name}: Only {len(sr.turns)} turns â€” aim for 8+ for max points"
                )
            if cq["questionsAsked"] < 4:
                hints.append(
                    f"ðŸ’¡ {sr.scenario_name}: Ask more questions (need â‰¥5 for max 4pts)"
                )
            if cq["redFlagIdentification"] < 8:
                hints.append(
                    f"ðŸ’¡ {sr.scenario_name}: Identify more red flags in responses"
                )
            if cq["informationElicitation"] < 7:
                hints.append(
                    f"ðŸ’¡ {sr.scenario_name}: Probe for more scammer details"
                )

            if d["engagementQuality"] < 10:
                hints.append(
                    f"ðŸ’¡ {sr.scenario_name}: Engagement quality {d['engagementQuality']}/10 â€” check duration/message count"
                )

            if sr.score.missing_required_fields:
                hints.append(
                    f"ðŸ”´ {sr.scenario_name}: Missing required fields: {sr.score.missing_required_fields}"
                )

        if hints:
            print("  IMPROVEMENT HINTS:")
            for h in hints:
                print(f"    {h}")
            print()


async def run_quick_eval(
    base_url: str = "http://localhost:8080",
    api_key: str = "test-api-key",
    suite: str = "standard",
    verbose: bool = True,
) -> EvalResult:
    """
    Convenience function to run a quick evaluation.
    
    Args:
        base_url: API server URL
        api_key: API key for auth
        suite: "standard" (3 scenarios) or "extended" (5 scenarios)
        verbose: Print progress
    
    Returns:
        EvalResult with full scoring breakdown
    """
    from eval_framework.scenarios import get_scenario_suite

    scenarios, weights = get_scenario_suite(suite)
    runner = EvalRunner(base_url=base_url, api_key=api_key)
    return await runner.run_evaluation(scenarios, weights, verbose=verbose)
